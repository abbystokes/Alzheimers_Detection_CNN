{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNeurodCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(44, 44))\n",
      "  (fc1): Linear(in_features=123904, out_features=500, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=500, out_features=3, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 178, 178]             320\n",
      "         MaxPool2d-2           [-1, 32, 89, 89]               0\n",
      "            Conv2d-3           [-1, 32, 87, 87]           9,248\n",
      "            Conv2d-4           [-1, 64, 85, 85]          18,496\n",
      " AdaptiveAvgPool2d-5           [-1, 64, 44, 44]               0\n",
      "            Linear-6                  [-1, 500]      61,952,500\n",
      "           Dropout-7                  [-1, 500]               0\n",
      "            Linear-8                    [-1, 3]           1,503\n",
      "================================================================\n",
      "Total params: 61,982,067\n",
      "Trainable params: 61,982,067\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 16.00\n",
      "Params size (MB): 236.44\n",
      "Estimated Total Size (MB): 252.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from src.data.dataset import load_dataset\n",
    "from src.models.models import SNeurodCNN\n",
    "\n",
    "class SNeurodCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNeurodCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((44, 44))\n",
    "        self.fc1 = nn.Linear(64 * 44 * 44, 500)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(500, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.adaptive_pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 44 * 44) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and print its structure\n",
    "model = SNeurodCNN()\n",
    "print(model)\n",
    "summary(model, input_size=(1, 180, 180))\n",
    "PATH = './models/sneurod_cnn.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer: Adam\n",
    "# Learning rate: 0.0001\n",
    "# Epochs: 100\n",
    "# Batch size: 32\n",
    "# Regularizers: Early stopping (patience = 5, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1: Train Loss: 2.1728, Val Loss: 1.0441\n",
      "Validation loss decreased (inf --> 35.499115). Saving model ...\n",
      "End of Epoch 2: Train Loss: 1.0569, Val Loss: 0.9774\n",
      "Validation loss decreased (35.499115 --> 33.231979). Saving model ...\n",
      "End of Epoch 3: Train Loss: 0.9827, Val Loss: 0.8834\n",
      "Validation loss decreased (33.231979 --> 30.033937). Saving model ...\n",
      "End of Epoch 4: Train Loss: 0.8782, Val Loss: 0.7049\n",
      "Validation loss decreased (30.033937 --> 23.965289). Saving model ...\n",
      "End of Epoch 5: Train Loss: 0.7733, Val Loss: 0.6142\n",
      "Validation loss decreased (23.965289 --> 20.882693). Saving model ...\n",
      "End of Epoch 6: Train Loss: 0.6453, Val Loss: 0.4549\n",
      "Validation loss decreased (20.882693 --> 15.465154). Saving model ...\n",
      "End of Epoch 7: Train Loss: 0.4934, Val Loss: 0.3008\n",
      "Validation loss decreased (15.465154 --> 10.226704). Saving model ...\n",
      "End of Epoch 8: Train Loss: 0.3824, Val Loss: 0.2693\n",
      "Validation loss decreased (10.226704 --> 9.156975). Saving model ...\n",
      "End of Epoch 9: Train Loss: 0.3050, Val Loss: 0.1437\n",
      "Validation loss decreased (9.156975 --> 4.887036). Saving model ...\n",
      "End of Epoch 10: Train Loss: 0.2007, Val Loss: 0.0779\n",
      "Validation loss decreased (4.887036 --> 2.647056). Saving model ...\n",
      "End of Epoch 11: Train Loss: 0.1729, Val Loss: 0.0636\n",
      "Validation loss decreased (2.647056 --> 2.162522). Saving model ...\n",
      "End of Epoch 12: Train Loss: 0.1323, Val Loss: 0.0408\n",
      "Validation loss decreased (2.162522 --> 1.388172). Saving model ...\n",
      "End of Epoch 13: Train Loss: 0.0839, Val Loss: 0.0245\n",
      "Validation loss decreased (1.388172 --> 0.833684). Saving model ...\n",
      "End of Epoch 14: Train Loss: 0.0637, Val Loss: 0.0172\n",
      "Validation loss decreased (0.833684 --> 0.583721). Saving model ...\n",
      "End of Epoch 15: Train Loss: 0.0494, Val Loss: 0.0107\n",
      "Validation loss decreased (0.583721 --> 0.362588). Saving model ...\n",
      "End of Epoch 16: Train Loss: 0.0518, Val Loss: 0.0118\n",
      "EarlyStopping counter: 1 out of 5\n",
      "End of Epoch 17: Train Loss: 0.0414, Val Loss: 0.0084\n",
      "Validation loss decreased (0.362588 --> 0.286690). Saving model ...\n",
      "End of Epoch 18: Train Loss: 0.0368, Val Loss: 0.0066\n",
      "Validation loss decreased (0.286690 --> 0.223418). Saving model ...\n",
      "End of Epoch 19: Train Loss: 0.0311, Val Loss: 0.0064\n",
      "Validation loss decreased (0.223418 --> 0.216923). Saving model ...\n",
      "End of Epoch 20: Train Loss: 0.0225, Val Loss: 0.0052\n",
      "Validation loss decreased (0.216923 --> 0.178122). Saving model ...\n",
      "End of Epoch 21: Train Loss: 0.0215, Val Loss: 0.0042\n",
      "Validation loss decreased (0.178122 --> 0.144300). Saving model ...\n",
      "End of Epoch 22: Train Loss: 0.0316, Val Loss: 0.0086\n",
      "EarlyStopping counter: 1 out of 5\n",
      "End of Epoch 23: Train Loss: 0.0310, Val Loss: 0.0056\n",
      "EarlyStopping counter: 2 out of 5\n",
      "End of Epoch 24: Train Loss: 0.0270, Val Loss: 0.0040\n",
      "Validation loss decreased (0.144300 --> 0.135794). Saving model ...\n",
      "End of Epoch 25: Train Loss: 0.0211, Val Loss: 0.0027\n",
      "Validation loss decreased (0.135794 --> 0.093004). Saving model ...\n",
      "End of Epoch 26: Train Loss: 0.0191, Val Loss: 0.0028\n",
      "EarlyStopping counter: 1 out of 5\n",
      "End of Epoch 27: Train Loss: 0.0281, Val Loss: 0.0066\n",
      "EarlyStopping counter: 2 out of 5\n",
      "End of Epoch 28: Train Loss: 0.0414, Val Loss: 0.0027\n",
      "Validation loss decreased (0.093004 --> 0.092382). Saving model ...\n",
      "End of Epoch 29: Train Loss: 0.0151, Val Loss: 0.0070\n",
      "EarlyStopping counter: 1 out of 5\n",
      "End of Epoch 30: Train Loss: 0.0290, Val Loss: 0.0060\n",
      "EarlyStopping counter: 2 out of 5\n",
      "End of Epoch 31: Train Loss: 0.0283, Val Loss: 0.0044\n",
      "EarlyStopping counter: 3 out of 5\n",
      "End of Epoch 32: Train Loss: 0.0160, Val Loss: 0.0012\n",
      "Validation loss decreased (0.092382 --> 0.041569). Saving model ...\n",
      "End of Epoch 33: Train Loss: 0.0065, Val Loss: 0.0008\n",
      "Validation loss decreased (0.041569 --> 0.026018). Saving model ...\n",
      "End of Epoch 34: Train Loss: 0.0049, Val Loss: 0.0004\n",
      "Validation loss decreased (0.026018 --> 0.014916). Saving model ...\n",
      "End of Epoch 35: Train Loss: 0.0063, Val Loss: 0.0011\n",
      "EarlyStopping counter: 1 out of 5\n",
      "End of Epoch 36: Train Loss: 0.0041, Val Loss: 0.0003\n",
      "Validation loss decreased (0.014916 --> 0.011694). Saving model ...\n",
      "End of Epoch 37: Train Loss: 0.0076, Val Loss: 0.0005\n",
      "EarlyStopping counter: 1 out of 5\n",
      "End of Epoch 38: Train Loss: 0.0052, Val Loss: 0.0003\n",
      "Validation loss decreased (0.011694 --> 0.010136). Saving model ...\n",
      "End of Epoch 39: Train Loss: 0.0047, Val Loss: 0.0004\n",
      "EarlyStopping counter: 1 out of 5\n",
      "End of Epoch 40: Train Loss: 0.0074, Val Loss: 0.0004\n",
      "EarlyStopping counter: 2 out of 5\n",
      "End of Epoch 41: Train Loss: 0.0046, Val Loss: 0.0002\n",
      "Validation loss decreased (0.010136 --> 0.008096). Saving model ...\n",
      "End of Epoch 42: Train Loss: 0.0063, Val Loss: 0.0003\n",
      "EarlyStopping counter: 1 out of 5\n",
      "End of Epoch 43: Train Loss: 0.0093, Val Loss: 0.0005\n",
      "EarlyStopping counter: 2 out of 5\n",
      "End of Epoch 44: Train Loss: 0.0095, Val Loss: 0.0005\n",
      "EarlyStopping counter: 3 out of 5\n",
      "End of Epoch 45: Train Loss: 0.0081, Val Loss: 0.0004\n",
      "EarlyStopping counter: 4 out of 5\n",
      "End of Epoch 46: Train Loss: 0.0047, Val Loss: 0.0005\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Module.load_state_dict of SNeurodCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(44, 44))\n",
       "  (fc1): Linear(in_features=123904, out_features=500, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=500, out_features=3, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, path=PATH):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# Load and prepare data\n",
    "classes = ('CN', 'AD', 'MCI')\n",
    "id2label = {i: classes[i] for i in range(len(classes))}\n",
    "label2id = {classes[i]: i for i in range(len(classes))}\n",
    "trainset = load_dataset(label2id=label2id, train=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)\n",
    "valset = load_dataset(label2id=label2id, train=False)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "# Instantiate the model and the EarlyStopping\n",
    "model = SNeurodCNN()\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop with early stopping and progress output\n",
    "for epoch in range(100):  # Number of epochs\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Optionally, print batch progress every few batches\n",
    "        if i % 100 == 99:  # Adjust the modulus value depending on your batch size and dataset size\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}: Loss: {train_loss / 100:.4f}')\n",
    "            train_loss = 0.0  # Reset train loss for the next set of batches\n",
    "\n",
    "    # Validation phase\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Print epoch-level progress\n",
    "    print(f'End of Epoch {epoch + 1}: Train Loss: {train_loss / len(trainloader):.4f}, Val Loss: {val_loss / len(valloader):.4f}')\n",
    "\n",
    "    # Early Stopping check\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# Load the best saved model\n",
    "model.load_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model and evaluate\n",
    "testset = load_dataset(label2id=label2id, train=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "net = SNeurodCNN()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
